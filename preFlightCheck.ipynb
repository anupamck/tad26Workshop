{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371680f2",
   "metadata": {},
   "source": [
    "# Pre-flight check\n",
    "\n",
    "The workshop uses an LLM from OpenAI in combination with LangSmith for tracing the calls made to this LLM. \n",
    "\n",
    "This notebook verifies your setup before running the RAG pipeline. It checks if\n",
    "- environment variables are loading properly\n",
    "- API keys are present\n",
    "- LLM is initialised\n",
    "- a test call runs to confirm **LangSmith** tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3f7d7b",
   "metadata": {},
   "source": [
    "**How Jupyter notebooks work** â€” A notebook is a list of **cells**. Each cell is either **code** (run by the kernel, e.g. Python) or **markdown** (formatted text). The kernel keeps variables and state between runs, so run cells **top to bottom** for this checklist. Outputs appear below each code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597cd337",
   "metadata": {},
   "source": [
    "## Load environment variables\n",
    "\n",
    "Load from `.env` (via `python-dotenv`) and check that `OPENAI_API_KEY` and `LANGSMITH_API_KEY` are set. Run this cell first so later cells can use the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026108df-4850-4372-bda1-e7b41d5dfbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv, dotenv_values\n",
    "\n",
    "# Load environment variables\n",
    "dotenv_path = find_dotenv(usecwd=True)\n",
    "print(\"dotenv_path:\", dotenv_path or \"NOT FOUND\")\n",
    "load_dotenv(dotenv_path=dotenv_path, override=True)\n",
    "\n",
    "# Check whether Open AI and Langsmith keys can be read from env\n",
    "open_ai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"OPENAI_API_KEY present in env?:\", open_ai_key is not None)\n",
    "\n",
    "langsmith_api_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "print(\"LANGSMITH_API_KEY present in env?:\", langsmith_api_key is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43adc8b",
   "metadata": {},
   "source": [
    "## Define LLM\n",
    "\n",
    "Initialize the chat model (e.g. `gpt-4o-mini`) with LangChain's `init_chat_model`. The same `llm` is used by the RAG pipeline and will be traced in LangSmith when env is configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5070809-d85c-49dc-bf5e-e525abed981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", verbose=True)\n",
    "print(\"LLM has been successfully initialized:\", llm.get_name() is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523d4a7c",
   "metadata": {},
   "source": [
    "## Test LLM via LangSmith\n",
    "\n",
    "Invoke the LLM with a simple prompt. If `LANGSMITH_API_KEY` and tracing (e.g. `LANGSMITH_TRACING=true` or `LANGCHAIN_TRACING_V2=true`) are set in `.env`, the run will appear in your LangSmith project so you can confirm the integration works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178f6a52",
   "metadata": {},
   "source": [
    "Run the cell below to send a test prompt. Check the printed response and your LangSmith project for the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7ea147-10ed-4945-945d-093f9b7cdc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test LLM via LangSmith: invoke with a simple prompt (trace will appear in LangSmith)\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "test_prompt = \"Reply with exactly: 'Pre-flight LLM check OK' and nothing else.\"\n",
    "response = llm.invoke([HumanMessage(content=test_prompt)])\n",
    "print(\"LLM response:\", response.content)\n",
    "print(\"LangSmith: check your project for this run's trace.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6eb052-4eea-4a9d-ae6e-5743fc10f99b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
